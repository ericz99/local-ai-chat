model:
  default: "llama3.2:latest"
  temperature: 0.7
  gpu_layers: 20
  max_context: 4096

privacy:
  encrypt_history: true

ui:
  theme: "dark"
  response_color: "cyan"
  prompt_symbol: "âž¤"
  show_thinking: true
